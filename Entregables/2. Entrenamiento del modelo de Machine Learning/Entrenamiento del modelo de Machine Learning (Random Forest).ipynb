{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oNRLCUQozsNs"
   },
   "source": [
    "# **TALLER 2 - Modelo Random Forest**\n",
    "\n",
    "* Daniel Felipe Vargas Ulloa\n",
    "* Andrés Francisco Borda Rincón"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E0hwr9MrzsNv"
   },
   "source": [
    "## **1. Preparación**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9G8qN090zsNv"
   },
   "source": [
    "Para la realización de este taller, se importan automaticamente las librerías necesarias y se descargará el conjunto de datos directamente del repositorio de Grocery Store Dataset donde se encuentra alojado. Para este ultimo paso es vital tener conexión a internet y tener git instalado en el entorno de trabajo como se especificó en la descripción del repositorio.\n",
    "\n",
    "**NOTA:** La ejecución de este notebook require al menos 14GB de RAM **disponible**. De lo contrario se encontrará con un error de out of memory error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nvgiv7H8zsNv"
   },
   "source": [
    "### **1.1 Importar librerías y descargar datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "CVjip5B8zsNw"
   },
   "outputs": [],
   "source": [
    "# Install all required libraries if not already installed using pip\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install -r requirements.txt | grep -v 'already satisfied'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "WYJhlx3XzsNx"
   },
   "outputs": [],
   "source": [
    "# pandas\n",
    "import pandas as pd\n",
    "\n",
    "# numpy version before 2.0.0\n",
    "import numpy as np\n",
    "\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# tensorflow\n",
    "import imgaug as ia\n",
    "\n",
    "# os\n",
    "import os\n",
    "\n",
    "# Image manipulation\n",
    "from PIL import Image\n",
    "import imgaug.augmenters as iaa\n",
    "import imageio.v2 as imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "NCH5jnRJzsNx"
   },
   "outputs": [],
   "source": [
    "# ensures the root directory is not the python path but the root of the project 'MINE-4101-Taller-2'\n",
    "if os.path.basename(os.getcwd()) == 'src':\n",
    "    os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "ORiBusNhzsNy"
   },
   "outputs": [],
   "source": [
    "# Clona el repositorio de github con el dataset si no existe ya en el entorno\n",
    "\n",
    "if not os.path.exists('GroceryStoreDataset'):\n",
    "    !git clone https://github.com/marcusklasson/GroceryStoreDataset.git\n",
    "\n",
    "# Carga el dataset\n",
    "df = pd.read_csv('GroceryStoreDataset/dataset/classes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "YQPHb3XazsNy"
   },
   "outputs": [],
   "source": [
    "# Configuración de pandas para extender el número de filas y columnas mostradas\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option('expand_frame_repr', False)\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "omdasSIuzsNz"
   },
   "source": [
    "### **1.2. Importar datos aumentados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f5NW1ibRzsNz"
   },
   "source": [
    "Ademas debemos realizar brevemente las transformaciones realizadas anterioremente en el notebook de preparación de datos para poder realizar el modelo Random Forest. En caso de que ya se haya realizado este proceso, se omite automáticamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "3e6ncAKbzsNz"
   },
   "outputs": [],
   "source": [
    "# Cargar la lista de imagenes de cada uno de los productos, por ahoar se usará granularidad de prpducto y no de tipo de producto\n",
    "\n",
    "# Carga los 3 datasets, GroceryStoreDataset/test, GroceryStoreDataset/train y GroceryStoreDataset/val\n",
    "\n",
    "# Define the column names\n",
    "column_names = ['Image Path', 'Class ID', 'Coarse Class ID']\n",
    "\n",
    "# Carga el dataset de entrenamiento\n",
    "df_train = pd.read_csv('GroceryStoreDataset/dataset/train.txt', names=column_names, header=None)\n",
    "\n",
    "# Carga el dataset de validación\n",
    "df_val = pd.read_csv('GroceryStoreDataset/dataset/val.txt', names=column_names, header=None)\n",
    "\n",
    "# Carga el dataset de prueba\n",
    "df_test = pd.read_csv('GroceryStoreDataset/dataset/test.txt', names=column_names, header=None)\n",
    "\n",
    "# Print the first few rows of each dataframe to verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K_4U3FQHzsNz",
    "outputId": "edf09c1e-c297-4908-b852-d59a71ef9131"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists. Skipping the process.\n"
     ]
    }
   ],
   "source": [
    "# Añade 'GroceryStoreDataset/dataset' al comienzo de cada ruta de imagen\n",
    "df_train['Image Path'] = 'GroceryStoreDataset/dataset/' + df_train['Image Path']\n",
    "df_val['Image Path'] = 'GroceryStoreDataset/dataset/' + df_val['Image Path']\n",
    "df_test['Image Path'] = 'GroceryStoreDataset/dataset/' + df_test['Image Path']\n",
    "\n",
    "# Check if the directory already exists\n",
    "if os.path.exists('GroceryStoreDataset/dataset/train_128x128'):\n",
    "    print(\"Directory already exists. Skipping the process.\")\n",
    "else:\n",
    "\n",
    "    # Create the directory\n",
    "    os.makedirs('GroceryStoreDataset/dataset/train_128x128', exist_ok=True)\n",
    "\n",
    "    # Function to resize and save the image\n",
    "    def resize_and_save(image_path, size, save_path):\n",
    "        with Image.open(image_path) as img:\n",
    "            img_resized = img.resize(size)\n",
    "            img_resized.save(save_path)\n",
    "\n",
    "    # Create a dictionary to map class_id and coarse_class_id to their names\n",
    "    class_id_to_name = df.set_index('Class ID (int)')['Class Name (str)'].to_dict()\n",
    "    coarse_class_id_to_name = df.set_index('Coarse Class ID (int)')['Coarse Class Name (str)'].to_dict()\n",
    "\n",
    "    # Resize and save all images in the train dataset\n",
    "    for index, row in df_train.iterrows():\n",
    "        image_path = row['Image Path']\n",
    "        class_id = row['Class ID']\n",
    "        coarse_class_id = row['Coarse Class ID']\n",
    "        class_name = class_id_to_name[class_id]\n",
    "        coarse_class_name = coarse_class_id_to_name[coarse_class_id]\n",
    "        image_name = image_path.split('/')[-1]\n",
    "        save_path = f'GroceryStoreDataset/dataset/train_128x128/{coarse_class_name}/{class_name}/{image_name}'\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        resize_and_save(image_path, (128, 128), save_path)\n",
    "\n",
    "    # Check the number of images in the resized directory, it should be the same as the original directory\n",
    "\n",
    "    # Count the number of images in the original directory\n",
    "    original_image_count = sum([len(files) for r, d, files in os.walk('GroceryStoreDataset/dataset/train')])\n",
    "    print(f\"Number of images in the original directory: {original_image_count}\")\n",
    "\n",
    "    # Count the number of images in the resized directory\n",
    "    resized_image_count = sum([len(files) for r, d, files in os.walk('GroceryStoreDataset/dataset/train_128x128')])\n",
    "    print(f\"Number of images in the resized directory: {resized_image_count}\")\n",
    "\n",
    "    # Check if the number of images in the original and resized directories are the same\n",
    "    if original_image_count == resized_image_count:\n",
    "        print(\"Number of images in the original and resized directories match.\")\n",
    "    else:\n",
    "        print(\"Number of images in the original and resized directories do not match.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q8P3XpCczsN0",
    "outputId": "1bca24d4-6f71-4a2a-fd83-931e81d718d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists. Skipping the process.\n"
     ]
    }
   ],
   "source": [
    "# Define the augmentation techniques\n",
    "augmenters = [\n",
    "    iaa.Fliplr(),  # Horizontal flip\n",
    "    iaa.Flipud(),  # Vertical flip\n",
    "    iaa.Crop(percent=(0.2)),  # Crop\n",
    "    iaa.Multiply((1.3)),  # Brightness\n",
    "    iaa.GaussianBlur(sigma=(1.2)),  # Blur\n",
    "    iaa.Affine(rotate=(53), mode='reflect'),\n",
    "    iaa.PerspectiveTransform(scale=(0.13))\n",
    "]\n",
    "\n",
    "# Reemplaza train en los paths con train_128x128\n",
    "df_train['Image Path'] = df_train['Image Path'].str.replace('train/', 'train_128x128/')\n",
    "\n",
    "# Remove Fruit/, Vegerable/ and Packages from the image path\n",
    "df_train['Image Path'] = df_train['Image Path'].str.replace('/Fruit/', '/')\n",
    "df_train['Image Path'] = df_train['Image Path'].str.replace('/Vegetables/', '/')\n",
    "df_train['Image Path'] = df_train['Image Path'].str.replace('/Packages/', '/')\n",
    "\n",
    "# Check if the directory already exists\n",
    "if os.path.exists('GroceryStoreDataset/dataset/train_augmented'):\n",
    "    print(\"Directory already exists. Skipping the process.\")\n",
    "else:\n",
    "    # Create the directory\n",
    "    os.makedirs('GroceryStoreDataset/dataset/train_augmented', exist_ok=True)\n",
    "\n",
    "    # Function to apply augmentations and save the image\n",
    "    def augment_and_save(image_path, augmenters, save_dir, image_name):\n",
    "      try:\n",
    "        with Image.open(image_path) as img:\n",
    "            img_np = np.array(img)\n",
    "            # Save the original image\n",
    "            original_save_path = os.path.join(save_dir, f'original_{image_name}')\n",
    "            img.save(original_save_path)\n",
    "            # Apply augmentations and save the augmented images\n",
    "            for i, augmenter in enumerate(augmenters):\n",
    "                augmented_img_np = augmenter(image=img_np)\n",
    "                augmented_img = Image.fromarray(augmented_img_np)\n",
    "                augmented_save_path = os.path.join(save_dir, f'augmented_{i}_{image_name}')\n",
    "                augmented_img.save(augmented_save_path)\n",
    "\n",
    "      except FileNotFoundError:\n",
    "        # Modify the path by repeating the subfolder name\n",
    "        base_path = 'GroceryStoreDataset/dataset/train_128x128/'\n",
    "        if base_path in image_path:\n",
    "            path_parts = image_path.split(base_path)\n",
    "            subfolder, remaining_path = path_parts[1].split('/', 1)\n",
    "            new_image_url = os.path.join(path_parts[0], base_path, subfolder, subfolder, remaining_path)\n",
    "\n",
    "            try:\n",
    "              with Image.open(new_image_url) as img:\n",
    "                img_np = np.array(img)\n",
    "                # Save the original image\n",
    "                original_save_path = os.path.join(save_dir, f'original_{image_name}')\n",
    "                img.save(original_save_path)\n",
    "                # Apply augmentations and save the augmented images\n",
    "                for i, augmenter in enumerate(augmenters):\n",
    "                    augmented_img_np = augmenter(image=img_np)\n",
    "                    augmented_img = Image.fromarray(augmented_img_np)\n",
    "                    augmented_save_path = os.path.join(save_dir, f'augmented_{i}_{image_name}')\n",
    "                    augmented_img.save(augmented_save_path)\n",
    "            except:\n",
    "              # raise FileNotFoundError(f\"File not found at either original or modified path: {image_path}\")\n",
    "              if subfolder == 'Brown-Cap-Mushroom':\n",
    "                  new_image_url = os.path.join(path_parts[0], base_path, 'Mushroom', subfolder, remaining_path)\n",
    "                  with Image.open(new_image_url) as img:\n",
    "                    img_np = np.array(img)\n",
    "                    # Save the original image\n",
    "                    original_save_path = os.path.join(save_dir, f'original_{image_name}')\n",
    "                    img.save(original_save_path)\n",
    "                    # Apply augmentations and save the augmented images\n",
    "                    for i, augmenter in enumerate(augmenters):\n",
    "                        augmented_img_np = augmenter(image=img_np)\n",
    "                        augmented_img = Image.fromarray(augmented_img_np)\n",
    "                        augmented_save_path = os.path.join(save_dir, f'augmented_{i}_{image_name}')\n",
    "                        augmented_img.save(augmented_save_path)\n",
    "\n",
    "\n",
    "        else:\n",
    "          raise FileNotFoundError(f\"File path does not contain expected base path: {image_path}\")\n",
    "\n",
    "\n",
    "\n",
    "    # Create a dictionary to map class_id and coarse_class_id to their names\n",
    "    class_id_to_name = df.set_index('Class ID (int)')['Class Name (str)'].to_dict()\n",
    "    coarse_class_id_to_name = df.set_index('Coarse Class ID (int)')['Coarse Class Name (str)'].to_dict()\n",
    "\n",
    "    # Apply augmentations and save all images in the train dataset\n",
    "    for index, row in df_train.iterrows():\n",
    "        image_path = row['Image Path']\n",
    "        class_id = row['Class ID']\n",
    "        coarse_class_id = row['Coarse Class ID']\n",
    "        class_name = class_id_to_name[class_id]\n",
    "        coarse_class_name = coarse_class_id_to_name[coarse_class_id]\n",
    "        image_name = image_path.split('/')[-1]\n",
    "        save_dir = f'GroceryStoreDataset/dataset/train_augmented/{coarse_class_name}/{class_name}'\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        augment_and_save(image_path, augmenters, save_dir, image_name)\n",
    "\n",
    "    # Check the number of images in the augmented directory, it should be the same as the original directory\n",
    "\n",
    "    # Count the number of images in the original directory\n",
    "    original_image_count = sum([len(files) for r, d, files in os.walk('GroceryStoreDataset/dataset/train')])\n",
    "    print(f\"Number of images in the original directory: {original_image_count}\")\n",
    "\n",
    "    # Count the number of images in the augmented directory\n",
    "    augmented_image_count = sum([len(files) for r, d, files in os.walk('GroceryStoreDataset/dataset/train_augmented')])\n",
    "    print(f\"Number of images in the augmented directory: {augmented_image_count}\")\n",
    "\n",
    "    # Check if the number of images in the original and augmented directories are the same by a factor of 8\n",
    "    if original_image_count * 8 == augmented_image_count:\n",
    "        print(\"Number of images in the original and augmented directories match by a factor of 8.\")\n",
    "    else:\n",
    "        print(\"Number of images in the original and augmented directories do not match.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BbwvRoQmzsN0",
    "outputId": "496c3104-621d-4b8b-f93d-86d6d9fe60ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the original DataFrame: 2640\n",
      "Size of the augmented DataFrame: 21120\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Function to generate augmented image paths\n",
    "def generate_augmented_paths(image_path):\n",
    "\n",
    "    base_path = image_path.replace('train/', 'train_augmented/')\n",
    "\n",
    "    # remove 'Fruit', 'Packages' and 'Vegeragles' as we're no longer grouping by type of product\n",
    "    base_path = base_path.replace('/Fruit/', '/')\n",
    "    base_path = base_path.replace('/Packages/', '/')\n",
    "    base_path = base_path.replace('/Vegetables/', '/')\n",
    "\n",
    "    # augmented image have the same path but have 'augmented_x_' prefix before the image name, so thats after the last '/'\n",
    "    # for example: 'train_augmented/Apple/Granny-Smith/Golden-Delicious_001.jpg' -> 'train_augmented/Apple/Granny-Smith/augmented_0_Golden-Delicious_001.jpg'\n",
    "    augmented_paths = []\n",
    "    for i in range(7):\n",
    "        augmented_path = base_path.rsplit('/', 1)[0] + f'/augmented_{i}_' + base_path.rsplit('/', 1)[1]\n",
    "        augmented_paths.append(augmented_path)\n",
    "\n",
    "    # also include the original image path\n",
    "    # for example: 'train_augmented/Apple/Granny-Smith/Golden-Delicious_001.jpg' -> 'train_augmented/Apple/Granny-Smith/original_Golden-Delicious_001.jpg'\n",
    "    original_path = base_path.rsplit('/', 1)[0] + f'/original_' + base_path.rsplit('/', 1)[1]\n",
    "    augmented_paths.append(original_path)\n",
    "    return augmented_paths\n",
    "\n",
    "# Create a new DataFrame to store the augmented image paths\n",
    "new_data = []\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "    class_id = row['Class ID']\n",
    "    coarse_class_id = row['Coarse Class ID']\n",
    "    original_image_path = row['Image Path']\n",
    "\n",
    "    augmented_paths = generate_augmented_paths(original_image_path)\n",
    "\n",
    "    for path in augmented_paths:\n",
    "        new_data.append({\n",
    "            'ClassId': class_id,\n",
    "            'coarse Class ID': coarse_class_id,\n",
    "            'image path': path\n",
    "        })\n",
    "\n",
    "# Create the new DataFrame\n",
    "augmented_df = pd.DataFrame(new_data, columns=['ClassId', 'coarse Class ID', 'image path'])\n",
    "\n",
    "# size of the original dataframe\n",
    "print(f\"Size of the original DataFrame: {df_train.shape[0]}\")\n",
    "\n",
    "# get the size of the augmented dataframe, it should be 8 times the size of the original dataframe\n",
    "print(f\"Size of the augmented DataFrame: {augmented_df.shape[0]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-T0cPGyXzsN1"
   },
   "source": [
    "### **1.3. Preparación de los datos para el entrenamiento**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufjdioGMzsN1"
   },
   "source": [
    "Hay 2 tareas que deberíamos realizar para preparar nuestros datos:\n",
    "\n",
    "1. \"Aplanar\" la imagen de tal manera que simplifiquemos las entradas para el modelo.\n",
    "2. Normalizar los valores de las imágenes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "NR5JUCDZzsN1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def flatten_and_normalize(images):\n",
    "    # Aplanar las imágenes\n",
    "    flattened_images = images.reshape(images.shape[0], -1)\n",
    "\n",
    "    # Normalizar los valores entre 0 y 1\n",
    "    normalized_images = flattened_images / 255.0\n",
    "\n",
    "    return normalized_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfLGZOJ3zsN1"
   },
   "source": [
    "# **2. Modelado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "IdR2Rf9ozsN1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "import os\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "import os\n",
    "from skimage.io import imread\n",
    "\n",
    "# Replace train128x128 for train_agumented in the image path\n",
    "augmented_df['image path'] = augmented_df['image path'].str.replace('train_128x128/', 'train_augmented/')\n",
    "\n",
    "# Define the function flatten_and_normalize\n",
    "def flatten_and_normalize(image_url, target_size=(128, 128)):\n",
    "    try:\n",
    "        image = imread(image_url)\n",
    "        image_resized = resize(image, target_size, anti_aliasing=True)\n",
    "        flattened_image = image_resized.flatten()\n",
    "        normalized_image = flattened_image / 255.0\n",
    "        normalized_image = normalized_image.astype(np.float16)\n",
    "        return normalized_image\n",
    "    except FileNotFoundError:\n",
    "        # Modify the path by repeating the subfolder name\n",
    "        base_path = 'GroceryStoreDataset/dataset/train_augmented/'\n",
    "        if base_path in image_url:\n",
    "            path_parts = image_url.split(base_path)\n",
    "            subfolder, remaining_path = path_parts[1].split('/', 1)\n",
    "            new_image_url = os.path.join(path_parts[0], base_path, subfolder, subfolder, remaining_path)\n",
    "\n",
    "            try:\n",
    "                # Retry with the modified path\n",
    "                image = imread(new_image_url)\n",
    "                image_resized = resize(image, target_size, anti_aliasing=True)\n",
    "                flattened_image = image_resized.flatten()\n",
    "                normalized_image = flattened_image / 255.0\n",
    "                normalized_image = normalized_image.astype(np.float16)\n",
    "                return normalized_image\n",
    "            except FileNotFoundError:\n",
    "                # Raise an error if the file is not found even after modification\n",
    "                if subfolder == 'Brown-Cap-Mushroom':\n",
    "                  new_image_url = os.path.join(path_parts[0], base_path, 'Mushroom', subfolder, remaining_path)\n",
    "                  # Retry with the modified path\n",
    "                  image = imread(new_image_url)\n",
    "                  image_resized = resize(image, target_size, anti_aliasing=True)\n",
    "                  flattened_image = image_resized.flatten()\n",
    "                  normalized_image = flattened_image / 255.0\n",
    "                  normalized_image = normalized_image.astype(np.float16)\n",
    "                  return normalized_image\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"File path does not contain expected base path: {image_url}\")\n",
    "\n",
    "\n",
    "# Aplicar la función a las imágenes en los DataFrames\n",
    "def preprocess_images(df, image_column):\n",
    "    # AN ARRAY flatten_and_normalize(url) for url in df[image_column]\n",
    "    return np.array([flatten_and_normalize(url) for url in df[image_column]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "carq9o9yopgM"
   },
   "source": [
    "### **2.1. Modelado a nivel de producto (manzana, aguacate, etc.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "41klKxQRsHOF"
   },
   "outputs": [],
   "source": [
    "# Train a Random Forest model with size limitations\n",
    "rf_classifierProducto = RandomForestClassifier(n_estimators=100,  # Reduce number of trees\n",
    "                                       max_depth=10,      # Limit tree depth\n",
    "                                       min_samples_split=5,  # Increase minimum samples for split\n",
    "                                       n_jobs=-1)           # Use all available cores\n",
    "\n",
    "# The best results from gridsearch have already been found.\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100, 200],         # Number of trees\n",
    "#     'max_depth': [None, 10, 20, 30],        # Maximum depth of each tree\n",
    "#     'min_samples_split': [2, 5, 10],        # Minimum number of samples to split an internal node\n",
    "#     'min_samples_leaf': [1, 2, 4],          # Minimum number of samples required to be at a leaf node\n",
    "#     'bootstrap': [True, False]              # Whether bootstrap samples are used when building trees\n",
    "# }\n",
    "\n",
    "# # Set up the GridSearchCV\n",
    "# grid_search = GridSearchCV(estimator=rf, param_grid=param_grid,\n",
    "#                            cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# # Fit the grid search to the data\n",
    "# grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dy6cQsDXpMYE",
    "outputId": "a42d5fb0-0507-45c7-ad0f-1cee406c818e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 49152 .That's the number of pixels in the images x3\n",
      "X_train shape: (21120, 49152)\n",
      "Training done\n"
     ]
    }
   ],
   "source": [
    "X_train = preprocess_images(augmented_df, 'image path')\n",
    "y_train = augmented_df['coarse Class ID'].values\n",
    "\n",
    "print(\"Number of features:\", X_train.shape[1], \".That's the number of pixels in the images x3\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "\n",
    "# Train the model\n",
    "rf_classifierProducto.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training done\")\n",
    "\n",
    "del X_train\n",
    "del y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Mgt6BXqRg5J",
    "outputId": "9ed975c2-c727-4de6-d401-fd39c4be9862"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_val shape: (296, 49152)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "X_val = preprocess_images(df_val, 'Image Path')\n",
    "y_val = df_val['Coarse Class ID'].values\n",
    "\n",
    "print(f\"X_val shape: {X_val.shape}\")\n",
    "\n",
    "# Predictions on validation and test sets\n",
    "y_val_pred = rf_classifierProducto.predict(X_val)\n",
    "\n",
    "del X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HzpBoOOUfNZC",
    "outputId": "da47da6a-ed0f-423e-ad7b-72c220f6a433"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.1867\n",
      "Recall: 0.2500\n",
      "F1-Score: 0.1671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Calculate Precision, Recall, and F1-Score\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_val, y_val_pred, average='weighted')\n",
    "\n",
    "# Print the results\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "del y_val_pred\n",
    "del y_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-G7p_wcrQGN"
   },
   "source": [
    "### **2.2. Modelado a nivel de marca (manzana Golden-Delicious, etc)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "6i6AQeJkrvYI"
   },
   "outputs": [],
   "source": [
    "# Train a Random Forest model with size limitations\n",
    "rf_classifierMarca = RandomForestClassifier(n_estimators=100,  # Reduce number of trees\n",
    "                                       max_depth=10,      # Limit tree depth\n",
    "                                       min_samples_split=5,  # Increase minimum samples for split\n",
    "                                       n_jobs=-1)           # Use all available cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W97GfKwlrQGQ",
    "outputId": "bc40bad0-bd07-43db-bd5b-524b9c014689"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 49152 .That's the number of pixels in the images x3\n",
      "X_train shape: (21120, 49152)\n",
      "Training done\n"
     ]
    }
   ],
   "source": [
    "X_train = preprocess_images(augmented_df, 'image path')\n",
    "y_train = augmented_df['ClassId'].values\n",
    "\n",
    "print(\"Number of features:\", X_train.shape[1], \".That's the number of pixels in the images x3\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "\n",
    "del augmented_df\n",
    "\n",
    "# Train the model\n",
    "rf_classifierMarca.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training done\")\n",
    "\n",
    "del X_train\n",
    "del y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wkWCzfw2rQGR",
    "outputId": "f9d1c9ef-9d2e-4a4f-d95f-6f58ee91463e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_val shape: (296, 49152)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "X_val = preprocess_images(df_val, 'Image Path')\n",
    "y_val = df_val['Class ID'].values\n",
    "del df_val\n",
    "\n",
    "print(f\"X_val shape: {X_val.shape}\")\n",
    "\n",
    "# Predictions on validation and test sets\n",
    "y_val_pred = rf_classifierMarca.predict(X_val)\n",
    "\n",
    "del X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YLpIUYcNrQGR",
    "outputId": "37b4ad82-cb9e-41ef-9bb6-3c542e6af470"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.1180\n",
      "Recall: 0.1284\n",
      "F1-Score: 0.0964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Calculate Precision, Recall, and F1-Score\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_val, y_val_pred, average='weighted')\n",
    "\n",
    "# Print the results\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2eFJStFi3yd4"
   },
   "source": [
    "## **3. Análisis de resultados del modelo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4yiQ7NX38g-"
   },
   "source": [
    "Usaremos los resultados del set de validación para analizar resultados del modelo, y posteriormente el set de prueba para compararlo con nuestro segundo modelo construido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w7HjWCb84K0e"
   },
   "source": [
    "En el contexto de clasificar productos de un supermercado, la métrica de accuracy (precisión) resulta más relevante que el recall (exactitud) porque nos interesa medir cuántas clasificaciones totales fueron correctas en comparación con todas las predicciones realizadas. El accuracy nos indica el porcentaje de productos que fueron correctamente clasificados del total, lo cual es clave para evaluar el rendimiento general de nuestro modelo en este caso.\n",
    "\n",
    "Por ejemplo, si clasificamos un conjunto de manzanas y obtenemos un accuracy del 95%, significa que el modelo asignó correctamente el producto a su categoría el 95% de las veces. En cambio, el recall mide cuántos de los productos de una categoría específica fueron identificados correctamente como tal.Esto puede ser menos informativo respecto al rendimiento del modelo en este escenario, ya que un alto recall para una categoría (como decir que de los 10 productos clasificados como aguacates, todos eran aguacates) no garantiza que todos los aguacates presentes en la muestra hayan sido identificados como tales.\n",
    "\n",
    "Por ejemplo, si hay 100 aguacates en total y el modelo solo clasificó correctamente 10 pero ignoró los otros 90, el recall seria alto (si no se clasificó nada mas como aguacate), lo cual no reflejaría bien el rendimiento general. En cambio, un buen accuracy asegura que el modelo sea consistente en su capacidad de identificar correctamente todos los tipos de productos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_yWmSoLW5MxI"
   },
   "source": [
    "### **3.1. Análisis de resultados de validación**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-nzuj6Es6foz"
   },
   "source": [
    "Los resultados obtenidos del modelo de clasificación no son alentadores. Posteriormente a haber definido el accuracy como métrica principal de evaluación y de realizar un exhaustivo proceso de optimización mediante grid search para los hiperparámetros, así como aplicar técnicas de aumento de datos, el modelo alcanzó un accuracy de apenas 0.18 a nivel de producto (por ejemplo, clasificar entre manzanas, aguacates, etc.) y 0.12 a nivel de subproducto o marca específica (como manzana Golden Delicious o Royal Gala). Estos resultados indican que el modelo tiene un desempeño significativamente limitado en la tarea de clasificación planteada.\n",
    "\n",
    "La baja capacidad del modelo para capturar tendencias en las imágenes, especialmente a nivel de subproducto, podría deberse a varias razones. En primer lugar, es posible que las características visuales entre diferentes subproductos sean demasiado sutiles o similares, dificultando que el modelo aprenda patrones distintivos. Además, es posible que la representación utilizada para los datos (un arreglo aplandado de los pixeles 128x128 de la imagen, con los canales RGB uno despues del otro) dificute al modelo la tarea de identificar tendencias significativas dentro de las imagenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "784Xhpf_7ARu"
   },
   "source": [
    "### **3.2. Análisis de resultados de prueba**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KIoup6-z7Dp3"
   },
   "source": [
    "Ahora se encontrarán los resultados sobre el conjunto de prueba, notese que estos no se compararán con el otro modelo dentro de este notebook, pero dentro del archivo de analizis de resultados y generación de valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4CRnG_Hl7qxf",
    "outputId": "89661aba-91a5-45e2-d73d-253f228d26a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (2485, 49152)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "X_test = preprocess_images(df_test, 'Image Path')\n",
    "y_test = df_test['Class ID'].values\n",
    "del df_test\n",
    "\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "\n",
    "# Predictions on validation and test sets\n",
    "y_test_pred = rf_classifierMarca.predict(X_test)\n",
    "\n",
    "del X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WqVgjfLw7TSr",
    "outputId": "f32159c9-7b7c-4ee4-f0f3-56ce33fd7c54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.1541\n",
      "Recall: 0.1815\n",
      "F1-Score: 0.1353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Calculate Precision, Recall, and F1-Score\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "# Print the results\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0bRcu5suARN4"
   },
   "source": [
    "Se usará esta metrica de precisión del 0.15 para comaprar nuestro modelo con nuestro segundo modelo construido en nuestro informe de comparación de resultados y generación de valor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.3. Elementos positivos y oportunidades de mejora**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La calidad del modelo se ve reflejada en sus métricas de accuracy (0.18 a nivel de producto y 0.08 a nivel de subproducto). A pesar de que estos resultados no son excelentes, se pueden identificar algunos aspectos positivos en el proceso de modelado que pudieron haber tenido un impacto en las métricas obtenidas. Entre ellos, la implementación de grid search para optimizar los hiperparámetros y las técnicas de aumento de datos fueron esfuerzos clave para mejorar la generalización del modelo y ampliar su capacidad de clasificación. El uso de grid search permitió identificar configuraciones de hiperparámetros más adecuadas, lo que, en teoría, debería haber ayudado a mejorar la capacidad del modelo para aprender patrones en los datos. La aumentación de datos, por otro lado, contribuyó a diversificar las muestras de entrenamiento y a reducir el riesgo de sobreajuste, lo que es particularmente útil en contextos con imágenes.\n",
    "\n",
    "Sin embargo, los resultados obtenidos indican que existen varias oportunidades de mejora que pueden abordarse para mejorar la precisión del modelo. Primero, una oportunidad clave sería mejorar la calidad y diversidad de las imágenes utilizadas en el entrenamiento. Incluir más variabilidad en términos de iluminación, perspectivas, resolución y otros factores podría ayudar a que el modelo generalice mejor las características distintivas entre las clases. Además, se podría explorar la posibilidad de analizar si nuestro modelo funciona mejor o peor para algunas clases en particular, y si es así, construir un segundo modelo especializado en clasificar las clases que este primer modelo no puede clasificar correctamente. Esto nos permitiría usar composición de modelos para mejorar la precisión general de nuestro sistema de clasificación."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
